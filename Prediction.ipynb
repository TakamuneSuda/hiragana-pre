{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測  \n",
    "実際に手書きひらがなの画像から、予測させる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from argparse import ArgumentParser\n",
    "# cnnモデルのインポート\n",
    "from Model import cnn_model_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの設定  \n",
    "\"model.py\"に保存した\"cnn_model_fn\"をmodel_fnとして設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './model/etl8g_convnet_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "etl8g_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn, model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 予測\n",
    "予測させたい手書きの画像を開き、予測できる形にする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('./pre_data/2.png')\n",
    "predict_data = np.asarray(image).reshape(1, 1024).astype(np.float32)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "予測させる画像を可視化すると"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2c051f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "def img_show(img):\n",
    "    imshow(img)\n",
    "\n",
    "img_show(predict_data.reshape(32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": predict_data},\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際に予測させる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model/etl8g_convnet_model/model.ckpt-33500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predict_results = list(etl8g_classifier.predict(predict_input_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "予測結果の出力は、確率がもっとも大きいラベルを表すclassesと、それぞれのラベルである確率を表すprobabilitiesとなっている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classes': 25, 'probabilities': array([1.39639821e-21, 1.66612968e-32, 1.56775156e-27, 3.15828147e-13,\n",
      "       1.88821829e-16, 5.02108595e-15, 2.34904148e-21, 4.83860954e-17,\n",
      "       1.23971915e-22, 8.38567094e-23, 2.06212169e-21, 1.94573353e-18,\n",
      "       1.40737253e-20, 1.24063812e-20, 3.20313966e-27, 6.20262435e-12,\n",
      "       3.37267906e-17, 1.75284341e-24, 1.01904623e-21, 6.93162689e-16,\n",
      "       2.61871889e-19, 6.95258263e-04, 2.69817209e-13, 2.92178933e-14,\n",
      "       4.23174021e-17, 9.99304771e-01, 2.49484944e-09, 7.52845540e-13,\n",
      "       2.97544330e-20, 5.06577483e-24, 2.60056840e-21, 4.74441941e-27,\n",
      "       3.08152783e-16, 1.48563006e-14, 5.65779575e-16, 1.59833014e-21,\n",
      "       1.57598679e-09, 3.97360882e-13, 1.97364952e-23, 1.99336507e-18,\n",
      "       1.57098286e-29, 2.77326962e-13, 1.66752787e-18, 2.27882282e-18,\n",
      "       2.19633822e-15, 3.04131812e-17, 6.26907985e-18, 1.84755885e-27,\n",
      "       5.94876197e-22, 2.89749829e-18, 8.69403505e-25, 1.71014281e-17,\n",
      "       7.40362300e-18, 1.82159126e-24, 6.84971252e-26, 2.12116267e-28,\n",
      "       1.34730700e-19, 3.64623153e-19, 6.97638969e-09, 5.65739980e-26,\n",
      "       2.48663964e-13, 1.09563136e-14, 2.27789476e-09, 6.12823754e-22,\n",
      "       1.96840729e-17, 1.97935552e-17, 1.33477705e-14, 7.27074148e-31,\n",
      "       8.84489008e-28, 7.92535293e-23, 4.77824540e-13, 2.03111190e-21,\n",
      "       3.66588224e-19, 1.01955839e-08, 6.11059489e-13], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "for i in predict_results:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数字だけでは何と予測したのかわからないので、前処理でも使用した'classmapping.csv'からひらがなのフレームを取得する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classmapping = pd.read_csv('../classmapping.csv', usecols=['ひらがな'], encoding='cp932')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predict_results[0]['classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "画像のひらがなは「た」です\n"
     ]
    }
   ],
   "source": [
    "print('画像のひらがなは「{}」です'.format(classmapping.iloc[result].ひらがな))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
